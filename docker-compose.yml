version: '3.8'
services:
  frontend:
    build: ./frontend/frontend-scaffold
    ports:
      - "3000:3000"
    volumes:
      - ./frontend/frontend-scaffold:/app
    command: npm run dev

  backend:
    build: ./backend
    ports:
      - "8080:8080"
    volumes:
      - ./backend:/go/src/app
    command: /server

  llm-service:
    build: ./llm-service
    environment:
      - PROMPT=Your default prompt or leave this to be configured elsewhere
    # Optional: Expose port if the LLM service provides an HTTP API or similar
    ports:
      - "5001:5000"